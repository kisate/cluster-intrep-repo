{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkcmtcc-user/openr1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_542776/818752847.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  activations = torch.load(activations_file)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import trange, tqdm\n",
    "from utils import Probe, set_seed, train_probe\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "activations_file = \"planning_activations_32b.pt\"\n",
    "metadata_file = \"planning_metadata.json\"\n",
    "\n",
    "activations = torch.load(activations_file)\n",
    "\n",
    "with open(metadata_file) as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "all_steps = set()\n",
    "\n",
    "for x in metadata:\n",
    "    dataset_idx = x[\"dataset_idx\"]\n",
    "    activation = activations[dataset_idx]\n",
    "\n",
    "    extracted_plan = x[\"bench_item\"][\"extracted_llm_plan\"]\n",
    "\n",
    "    validity = x[\"bench_item\"][\"llm_validity\"]\n",
    "\n",
    "    if validity != 1:\n",
    "        continue\n",
    "\n",
    "    steps = set(extracted_plan.split(\"\\n\"))\n",
    "\n",
    "    steps = {step for step in steps if step != \"\"}\n",
    "\n",
    "    all_steps.update(steps)\n",
    "\n",
    "    think_pos = x[\"think_pos\"]\n",
    "\n",
    "    dataset.append({\n",
    "        \"activations\": activation,\n",
    "        \"steps\": steps,\n",
    "        \"think_pos\": think_pos\n",
    "    })\n",
    "\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "test_size = 0.2\n",
    "test_size = int(len(dataset) * test_size)\n",
    "\n",
    "train_dataset = dataset[:-test_size]\n",
    "test_dataset = dataset[-test_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 5120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "{'(stack d a)', '(stack k f)', '(stack h f)', '(unstack d j)', '(unstack j g)', '(stack b h)', '(stack l b)', '(unstack j i)', '(stack c b)', '(stack g b)', '(unstack b c)', '(unstack f c)', '(unstack b f)', '(stack b f)', '(pick-up i)', '(unstack f e)', '(stack a l)', '(unstack m f)', '(stack m j)', '(unstack e f)', '(stack f k)', '(unstack e c)', '(unstack a h)', '(pick-up h)', '(stack i h)', '(unstack n f)', '(stack e f)', '(unstack c e)', '(stack k j)', '(pick-up j)', '(stack j g)', '(put-down c)', '(stack c f)', '(unstack h d)', '(unstack d b)', '(stack f a)', '(unstack e d)', '(stack h c)', '(stack n l)', '(stack j k)', '(stack c e)', '(pick-up e)', '(pick-up f)', '(unstack g c)', '(unstack h e)', '(unstack f h)', '(stack d g)', '(stack g c)', '(unstack g l)', '(stack m d)', '(stack f h)', '(stack c a)', '(put-down e)', '(unstack a g)', '(put-down h)', '(unstack b a)', '(stack c j)', '(put-down l)', '(unstack g i)', '(stack k e)', '(unstack h a)', '(stack b i)', '(unstack c k)', '(stack g a)', '(unstack c f)', '(stack b g)', '(stack i g)', '(stack a m)', '(put-down j)', '(stack a i)', '(unstack h b)', '(pick-up b)', '(put-down k)', '(unstack l f)', '(unstack a d)', '(unstack i f)', '(unstack h f)', '(stack h j)', '(stack j c)', '(stack b d)', '(unstack c h)', '(stack e h)', '(put-down i)', '(stack a h)', '(stack g j)', '(stack g e)', '(stack j a)', '(stack j b)', '(unstack c i)', '(stack d b)', '(unstack a f)', '(stack i j)', '(unstack j m)', '(stack d j)', '(unstack d i)', '(unstack c a)', '(unstack j h)', '(stack c h)', '(stack g f)', '(unstack g h)', '(stack a c)', '(stack i f)', '(unstack k b)', '(stack i e)', '(unstack d h)', '(stack e k)', '(stack f i)', '(stack h i)', '(put-down f)', '(unstack j e)', '(stack e g)', '(unstack d m)', '(stack a b)', '(stack d h)', '(unstack e k)', '(unstack g b)', '(unstack b l)', '(unstack h g)', '(unstack j k)', '(pick-up m)', '(unstack g f)', '(unstack g e)', '(stack h k)', '(stack f d)', '(unstack k e)', '(put-down a)', '(unstack l n)', '(unstack l a)', '(unstack g j)', '(stack a f)', '(stack d e)', '(stack d c)', '(unstack f b)', '(unstack d g)', '(unstack c d)', '(stack j l)', '(unstack k j)', '(stack f n)', '(unstack e h)', '(unstack e g)', '(stack g d)', '(put-down n)', '(stack j e)', '(unstack m k)', '(stack k g)', '(stack d f)', '(stack i c)', '(unstack i a)', '(stack m e)', '(unstack c b)', '(stack i b)', '(pick-up n)', '(unstack l i)', '(stack b m)', '(unstack f d)', '(stack j n)', '(unstack a i)', '(stack e j)', '(pick-up l)', '(unstack d a)', '(stack l c)', '(stack b c)', '(stack f c)', '(stack h b)', '(unstack e i)', '(stack h g)', '(unstack j f)', '(stack b a)', '(unstack i d)', '(unstack i h)', '(stack a e)', '(unstack c j)', '(stack l a)', '(unstack b g)', '(stack e c)', '(stack e b)', '(stack d i)', '(stack e i)', '(stack c g)', '(unstack l j)', '(stack i d)', '(pick-up k)', '(stack h e)', '(stack f b)', '(pick-up c)', '(unstack b e)', '(stack g h)', '(unstack f j)', '(stack h d)', '(unstack h c)', '(stack f e)', '(unstack a b)', '(stack l j)', '(put-down m)', '(stack a d)', '(unstack g a)', '(unstack a c)', '(unstack d f)', '(unstack f a)', '(unstack b k)', '(unstack e b)', '(unstack a l)', '(unstack d e)', '(stack b j)', '(pick-up a)', '(unstack a e)', '(stack b e)', '(unstack f g)', '(stack k i)', '(unstack b j)', '(stack f g)', '(stack k a)', '(unstack j a)', '(stack i a)', '(stack e a)', '(unstack i g)', '(stack h a)', '(stack i k)', '(unstack c g)', '(stack m l)', '(pick-up g)', '(stack f l)', '(unstack n h)', '(put-down g)', '(put-down d)', '(stack e d)', '(stack c k)', '(unstack e a)', '(stack j i)', '(unstack g k)', '(unstack b i)', '(unstack g d)', '(pick-up d)', '(stack c i)', '(put-down b)', '(unstack b d)', '(unstack e m)', '(stack n e)', '(stack c d)', '(unstack a m)', '(stack g m)', '(unstack d c)', '(stack a g)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(all_steps))\n",
    "print(all_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_items = {step: [] for step in all_steps}\n",
    "\n",
    "for item in train_dataset:\n",
    "    activations = item[\"activations\"]\n",
    "    steps = item[\"steps\"]\n",
    "    think_pos = item[\"think_pos\"]\n",
    "\n",
    "    for step in steps:\n",
    "        train_data_items[step].append((activations, think_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "counts = {step: len(train_data_items[step]) for step in all_steps}\n",
    "\n",
    "cutoff = 10\n",
    "\n",
    "all_steps = [step for step in all_steps if counts[step] > cutoff]\n",
    "\n",
    "print(len(all_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = {\n",
    "    \"train\": {step: [] for step in all_steps},\n",
    "    \"test\": {step: [] for step in all_steps}\n",
    "}\n",
    "negative_data = {\n",
    "    \"train\": {step: [] for step in all_steps},\n",
    "    \"test\": {step: [] for step in all_steps}\n",
    "}\n",
    "\n",
    "for x in train_dataset:\n",
    "    activations = x[\"activations\"]\n",
    "    steps = x[\"steps\"]\n",
    "    think_pos = x[\"think_pos\"]\n",
    "\n",
    "    for step in all_steps:\n",
    "        if step in steps:\n",
    "            positive_data[\"train\"][step].append((activations, think_pos, True))\n",
    "        else:\n",
    "            negative_data[\"train\"][step].append((activations, think_pos, False))\n",
    "\n",
    "for x in test_dataset:\n",
    "    activations = x[\"activations\"]\n",
    "    steps = x[\"steps\"]\n",
    "    think_pos = x[\"think_pos\"]\n",
    "\n",
    "    for step in all_steps:\n",
    "        if step in steps:\n",
    "            positive_data[\"test\"][step].append((activations, think_pos, True))\n",
    "        else:\n",
    "            negative_data[\"test\"][step].append((activations, think_pos, False))\n",
    "\n",
    "final_steps = set()\n",
    "\n",
    "for step in all_steps:\n",
    "    if len(positive_data[\"train\"][step]) > 10 and len(negative_data[\"train\"][step]) > 10 and len(positive_data[\"test\"][step]) > 3 and len(negative_data[\"test\"][step]) > 3:\n",
    "        final_steps.add(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(stack d a) 21 142 7 33\n",
      "(pick-up b) 118 45 29 11\n",
      "(pick-up c) 128 35 29 11\n",
      "(unstack a d) 14 149 4 36\n",
      "(unstack a b) 24 139 6 34\n",
      "(stack a d) 22 141 6 34\n",
      "(stack c b) 31 132 10 30\n",
      "(unstack a c) 22 141 7 33\n",
      "(stack b d) 27 136 7 33\n",
      "(pick-up i) 19 144 5 35\n",
      "(stack c d) 22 141 6 34\n",
      "(stack d f) 12 151 4 36\n",
      "(pick-up a) 121 42 31 9\n",
      "(stack b e) 12 151 4 36\n",
      "(pick-up h) 24 139 8 32\n",
      "(stack e f) 14 149 4 36\n",
      "(unstack c a) 27 136 7 33\n",
      "(unstack c b) 21 142 6 34\n",
      "(put-down c) 87 76 22 18\n",
      "(unstack d b) 13 150 4 36\n",
      "(stack a c) 38 125 8 32\n",
      "(pick-up g) 38 125 13 27\n",
      "(put-down g) 33 130 7 33\n",
      "(stack b c) 36 127 7 33\n",
      "(put-down d) 84 79 14 26\n",
      "(stack c e) 14 149 4 36\n",
      "(pick-up e) 73 90 15 25\n",
      "(pick-up f) 60 103 11 29\n",
      "(put-down f) 38 125 10 30\n",
      "(unstack e a) 12 151 5 35\n",
      "(stack a b) 27 136 14 26\n",
      "(stack b a) 30 133 8 32\n",
      "(stack c a) 40 123 7 33\n",
      "(put-down e) 60 103 14 26\n",
      "(unstack b a) 24 139 6 34\n",
      "(stack e b) 12 151 5 35\n",
      "(put-down a) 77 86 22 18\n",
      "(pick-up d) 115 48 26 14\n",
      "(put-down b) 87 76 21 19\n",
      "(unstack b d) 18 145 6 34\n",
      "(stack d c) 18 145 8 32\n"
     ]
    }
   ],
   "source": [
    "for step in final_steps:\n",
    "    print(step, len(positive_data[\"train\"][step]), len(negative_data[\"train\"][step]), len(positive_data[\"test\"][step]), len(negative_data[\"test\"][step]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbeDataset(Dataset):\n",
    "    def __init__(self, dataset, probe_pos, step, positive_data, negative_data, aggregate=False, balance=True):\n",
    "        self.dataset = dataset\n",
    "        self.probe_pos = probe_pos\n",
    "        self.aggregate = aggregate\n",
    "\n",
    "        self.positive_samples, self.negative_samples = negative_data[step], positive_data[step]\n",
    "\n",
    "        # fix imbalance\n",
    "\n",
    "        n_positive = len(self.positive_samples)\n",
    "        n_negative = len(self.negative_samples)\n",
    "\n",
    "        n_samples = min(n_positive, n_negative)\n",
    "\n",
    "        if balance:\n",
    "            self.positive_samples = self.positive_samples[:n_samples]\n",
    "            self.negative_samples = self.negative_samples[:n_samples]\n",
    "\n",
    "        self.samples = self.positive_samples + self.negative_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, _, is_positive = self.samples[idx]\n",
    "\n",
    "        if self.aggregate:\n",
    "            sample = sample[:self.probe_pos]\n",
    "            # sample = torch.mean(sample, dim=0)\n",
    "            sample = sample.view(-1)    \n",
    "        else:\n",
    "            sample = sample[self.probe_pos]\n",
    "\n",
    "        return {\n",
    "            \"inputs\": sample,\n",
    "            \"label\": int(is_positive)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "for step in final_steps:\n",
    "    train_datasets[step] = ProbeDataset(dataset, 600, step, positive_data[\"train\"], negative_data[\"train\"], aggregate=False)\n",
    "    test_datasets[step] = ProbeDataset(dataset, 600, step, positive_data[\"test\"], negative_data[\"test\"], aggregate=False, balance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = {\n",
    "    step: Probe(n_dim, 2) for step in final_steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n",
    "\n",
    "for step in final_steps:\n",
    "    accuracy[step] = train_probe(probes[step], train_datasets[step], test_datasets[step], n_epochs=4, silent=True, lr=1e-4)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(stack d a) 0.175 21 142 7 33 0.825\n",
      "(pick-up b) 0.275 118 45 29 11 0.725\n",
      "(pick-up c) 0.275 128 35 29 11 0.725\n",
      "(unstack a d) 0.525 14 149 4 36 0.9\n",
      "(unstack a b) 0.15 24 139 6 34 0.85\n",
      "(stack a d) 0.15 22 141 6 34 0.85\n",
      "(stack c b) 0.4 31 132 10 30 0.75\n",
      "(unstack a c) 0.425 22 141 7 33 0.825\n",
      "(stack b d) 0.825 27 136 7 33 0.825\n",
      "(pick-up i) 0.875 19 144 5 35 0.875\n",
      "(stack c d) 0.15 22 141 6 34 0.85\n",
      "(stack d f) 0.9 12 151 4 36 0.9\n",
      "(pick-up a) 0.225 121 42 31 9 0.775\n",
      "(stack b e) 0.625 12 151 4 36 0.9\n",
      "(pick-up h) 0.325 24 139 8 32 0.8\n",
      "(stack e f) 0.875 14 149 4 36 0.9\n",
      "(unstack c a) 0.225 27 136 7 33 0.825\n",
      "(unstack c b) 0.15 21 142 6 34 0.85\n",
      "(put-down c) 0.675 87 76 22 18 0.55\n",
      "(unstack d b) 0.3 13 150 4 36 0.9\n",
      "(stack a c) 0.2 38 125 8 32 0.8\n",
      "(pick-up g) 0.675 38 125 13 27 0.675\n",
      "(put-down g) 0.225 33 130 7 33 0.825\n",
      "(stack b c) 0.275 36 127 7 33 0.825\n",
      "(put-down d) 0.45 84 79 14 26 0.65\n",
      "(stack c e) 0.275 14 149 4 36 0.9\n",
      "(pick-up e) 0.625 73 90 15 25 0.625\n",
      "(pick-up f) 0.725 60 103 11 29 0.725\n",
      "(put-down f) 0.25 38 125 10 30 0.75\n",
      "(unstack e a) 0.825 12 151 5 35 0.875\n",
      "(stack a b) 0.35 27 136 14 26 0.65\n",
      "(stack b a) 0.825 30 133 8 32 0.8\n",
      "(stack c a) 0.175 40 123 7 33 0.825\n",
      "(put-down e) 0.625 60 103 14 26 0.65\n",
      "(unstack b a) 0.2 24 139 6 34 0.85\n",
      "(stack e b) 0.125 12 151 5 35 0.875\n",
      "(put-down a) 0.5 77 86 22 18 0.55\n",
      "(pick-up d) 0.35 115 48 26 14 0.65\n",
      "(put-down b) 0.55 87 76 21 19 0.525\n",
      "(unstack b d) 0.15 18 145 6 34 0.85\n",
      "(stack d c) 0.225 18 145 8 32 0.8\n"
     ]
    }
   ],
   "source": [
    "for step in final_steps:\n",
    "    propotion = len(positive_data[\"test\"][step]) / (len(positive_data[\"test\"][step]) + len(negative_data[\"test\"][step]))\n",
    "    print(step, accuracy[step], len(positive_data[\"train\"][step]), len(negative_data[\"train\"][step]), len(positive_data[\"test\"][step]), len(negative_data[\"test\"][step]), max(propotion, 1 - propotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
