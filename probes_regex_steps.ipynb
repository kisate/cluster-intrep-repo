{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from cluster_intrep_repo.utils import initialize_tokenizer, tokenize_blocksworld_generation, THINK_TOKEN\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "compute_dtype = torch.bfloat16\n",
    "device   = 'cuda'\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"planning_metadata.json\") as f:\n",
    "    metadata = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n"
     ]
    }
   ],
   "source": [
    "n_blocks = 8\n",
    "n_instances = 10000\n",
    "\n",
    "correct_instances = []\n",
    "\n",
    "import re\n",
    "\n",
    "regex = re.compile(r\"stack is [A-Z](?:\\s?(?:->|-|,|→|on)\\s?[A-Z])*\")\n",
    "\n",
    "regex2 = re.compile(r\"stack is [A-Z] (table)\")\n",
    "regex3 = re.compile(r\"stack is [A-Z] with\")\n",
    "\n",
    "def extract_blocks(text):\n",
    "    if \"on\" in text:\n",
    "        text = text[::-1]\n",
    "\n",
    "    return re.findall(r\"[A-Z]\", text)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# re.findall(regex, text)\n",
    "for i, x in enumerate(metadata):\n",
    "    if x[\"bench_item\"][\"Number of blocks\"] <= n_blocks and x[\"bench_item\"][\"llm_correct\"] == True: \n",
    "        text = x[\"bench_item\"][\"full_response\"]\n",
    "\n",
    "        matches = re.findall(regex, text)\n",
    "        matches2 = re.findall(regex2, text)\n",
    "        matches3 = re.findall(regex3, text)\n",
    "\n",
    "        if len(matches) > 2 and len(matches2) == 0 and len(matches3) == 0:\n",
    "            # print(i, re.findall(regex, text))\n",
    "            all_stacks = [extract_blocks(y) for y in matches]\n",
    "\n",
    "            max_len = max([len(y) for y in all_stacks])\n",
    "            inner_stacks = [y for y in all_stacks if len(y) > 1 and len(y) < max_len]\n",
    "\n",
    "            if len(inner_stacks) > 0:\n",
    "                correct_instances.append(x)\n",
    "                \n",
    "print(len(correct_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = initialize_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocksworld_type = \"big\"\n",
    "\n",
    "dataset = load_dataset(f\"dmitriihook/deepseek-r1-qwen-32b-planning-{blocksworld_type}\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:13<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model     = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=compute_dtype, attn_implementation=\"sdpa\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 327/327 [05:32<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# [src; dest]\n",
    "\n",
    "layer_hidden_states = defaultdict(list)\n",
    "\n",
    "n_last_layers = 10\n",
    "\n",
    "for instance in tqdm(correct_instances):\n",
    "    row = dataset[instance[\"dataset_idx\"]]\n",
    "    chat = tokenize_blocksworld_generation(tokenizer, row)\n",
    "\n",
    "    think_pos = torch.where(chat.squeeze() == THINK_TOKEN)[0]\n",
    "\n",
    "    if len(think_pos) == 0:\n",
    "        for j in range(n_last_layers):\n",
    "            layer_hidden_states[j].append(None)\n",
    "\n",
    "        continue\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(chat.to(device), output_hidden_states=True)\n",
    "\n",
    "        for j in range(n_last_layers):\n",
    "            hidden_states = outputs.hidden_states[-1 - j]\n",
    "            layer_hidden_states[j].append(hidden_states[0].float().cpu().numpy())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "327it [00:04, 68.36it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "for i, instance in tqdm(enumerate(correct_instances)):\n",
    "    row = dataset[instance[\"dataset_idx\"]]\n",
    "    text =  instance[\"bench_item\"][\"full_response\"]\n",
    "\n",
    "    data_item = {\n",
    "        \"stacks\": [],\n",
    "        \"positions\": [],\n",
    "        \"idx\": i\n",
    "    }\n",
    "\n",
    "    matches = re.findall(regex, text)\n",
    "\n",
    "    all_stacks = [extract_blocks(y) for y in matches]\n",
    "\n",
    "    max_len = max([len(y) for y in all_stacks])\n",
    "\n",
    "    for match in re.finditer(regex, text):\n",
    "\n",
    "        stack = extract_blocks(match.group(0))\n",
    "\n",
    "        if len(stack) == 1:\n",
    "            continue\n",
    "\n",
    "        if len(stack) == max_len:\n",
    "            continue\n",
    "\n",
    "        start = match.start()\n",
    "        \n",
    "        tokens = tokenize_blocksworld_generation(tokenizer, row, generation=text[:start])[0]\n",
    "\n",
    "        stack = extract_blocks(match.group(0))\n",
    "\n",
    "        data_item[\"stacks\"].append(stack)\n",
    "        data_item[\"positions\"].append(len(tokens))\n",
    "\n",
    "    training_data.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.8\n",
    "n_train = int(len(training_data) * train_test_split)\n",
    "\n",
    "print(n_train)\n",
    "\n",
    "training_data, testing_data = training_data[:n_train], training_data[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data = []\n",
    "expanded_testing_data = []\n",
    "\n",
    "for data in training_data:\n",
    "    for stack, pos in zip(data[\"stacks\"], data[\"positions\"]):\n",
    "        expanded_training_data.append({\n",
    "            \"stack\": stack,\n",
    "            \"position\": pos,\n",
    "            \"idx\": data[\"idx\"]\n",
    "        })\n",
    "\n",
    "for data in testing_data:\n",
    "    for stack, pos in zip(data[\"stacks\"], data[\"positions\"]):\n",
    "        expanded_testing_data.append({\n",
    "            \"stack\": stack,\n",
    "            \"position\": pos,\n",
    "            \"idx\": data[\"idx\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expanded_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stack': ['B', 'E', 'C', 'D'], 'position': 1755, 'idx': 261}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_testing_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "block_to_idx = {f\"{chr(65 + i)}\": i + 1 for i in range(n_blocks)}\n",
    "\n",
    "def stack_to_labels(stack, n_blocks):\n",
    "    labels = torch.zeros(n_blocks,  dtype=torch.int64)\n",
    "    \n",
    "    for i, block in enumerate(stack[:n_blocks]):\n",
    "        labels[i] = block_to_idx[block]\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "class StackProbing(Dataset):\n",
    "    def __init__(self, data, layer_hidden_states, layer):\n",
    "        self.data = data\n",
    "        self.layer_hidden_states = layer_hidden_states\n",
    "        self.layer = layer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        hidden_states = self.layer_hidden_states[self.layer][item[\"idx\"]][item[\"position\"] - 3:item[\"position\"]].mean(axis=0)\n",
    "\n",
    "        return {\n",
    "            \"input\": hidden_states,\n",
    "            \"labels\": stack_to_labels(item[\"stack\"], n_blocks),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = StackProbing(expanded_training_data, layer_hidden_states, 0)\n",
    "testing_dataset = StackProbing(expanded_testing_data, layer_hidden_states, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': array([ 0.84309894,  0.35677084,  0.4671224 , ..., -0.48453775,\n",
       "         1.4309896 ,  1.4166666 ], dtype=float32),\n",
       " 'labels': tensor([4, 3, 2, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateProbe(torch.nn.Module):\n",
    "    def __init__(self, n_blocks, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.layer1 = torch.nn.Linear(input_size, hidden_size, dtype=torch.float32)\n",
    "        self.layer2 = torch.nn.Linear(input_size, (n_blocks + 1) * n_blocks, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = self.layer2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.layer2(x)\n",
    "        return x.view(x.shape[0], -1, n_blocks)\n",
    "\n",
    "\n",
    "n_dim = 5120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "probe = StateProbe(n_blocks, n_dim, 1000).to(device)\n",
    "\n",
    "optimizer = Adam(probe.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy: 0.5802734345197678\n",
      "Epoch 1 Accuracy: 0.5833203122019768\n",
      "Epoch 2 Accuracy: 0.6080664023756981\n",
      "Epoch 3 Accuracy: 0.61279296875\n",
      "Epoch 4 Accuracy: 0.6285351514816284\n",
      "Epoch 5 Accuracy: 0.6127343699336052\n",
      "Epoch 6 Accuracy: 0.6422656178474426\n",
      "Epoch 7 Accuracy: 0.6302148401737213\n",
      "Epoch 8 Accuracy: 0.6348828077316284\n",
      "Epoch 9 Accuracy: 0.6261913999915123\n",
      "Epoch 10 Accuracy: 0.6357812434434891\n",
      "Epoch 11 Accuracy: 0.6322460919618607\n",
      "Epoch 12 Accuracy: 0.6314062476158142\n",
      "Epoch 13 Accuracy: 0.6363281160593033\n",
      "Epoch 14 Accuracy: 0.6363476514816284\n",
      "Epoch 15 Accuracy: 0.6329882740974426\n",
      "Epoch 16 Accuracy: 0.6417773365974426\n",
      "Epoch 17 Accuracy: 0.6394726485013962\n",
      "Epoch 18 Accuracy: 0.6336328089237213\n",
      "Epoch 19 Accuracy: 0.6461718678474426\n",
      "Epoch 20 Accuracy: 0.6436718702316284\n",
      "Epoch 21 Accuracy: 0.6414257735013962\n",
      "Epoch 22 Accuracy: 0.6386523395776749\n",
      "Epoch 23 Accuracy: 0.6440234333276749\n",
      "Epoch 24 Accuracy: 0.6406640559434891\n",
      "Epoch 25 Accuracy: 0.6370507776737213\n",
      "Epoch 26 Accuracy: 0.6449804604053497\n",
      "Epoch 27 Accuracy: 0.6487499922513962\n",
      "Epoch 28 Accuracy: 0.6509765535593033\n",
      "Epoch 29 Accuracy: 0.6456835865974426\n",
      "Epoch 30 Accuracy: 0.6485546827316284\n",
      "Epoch 31 Accuracy: 0.6473437398672104\n",
      "Epoch 32 Accuracy: 0.6522265523672104\n",
      "Epoch 33 Accuracy: 0.647714838385582\n",
      "Epoch 34 Accuracy: 0.6472070217132568\n",
      "Epoch 35 Accuracy: 0.6436132788658142\n",
      "Epoch 36 Accuracy: 0.6475585848093033\n",
      "Epoch 37 Accuracy: 0.6434570252895355\n",
      "Epoch 38 Accuracy: 0.6518163979053497\n",
      "Epoch 39 Accuracy: 0.6504101604223251\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "for epoch in range(n_epochs):\n",
    "    probe.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input = batch[\"input\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        output = probe(input)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(batch)\n",
    "        n_samples += len(batch)\n",
    "\n",
    "    probe.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        n_samples = 0\n",
    "        for batch in test_loader:\n",
    "            input = batch[\"input\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            output = probe(input) \n",
    "\n",
    "            accuracy = (output.argmax(dim=-2) == labels).float().mean()\n",
    "\n",
    "            total_loss += accuracy.item() * len(batch)\n",
    "            n_samples += len(batch)\n",
    "\n",
    "        print(f\"Epoch {epoch} Accuracy: {total_loss / n_samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'D', 'E', 'C', '@', '@'] ['E', 'A', 'D', 'B', '@', '@']\n",
      "['B', 'D', 'E', 'C', '@', '@'] ['E', 'A', 'D', 'B', '@', '@']\n",
      "['C', 'B', 'D', 'B', '@', '@'] ['C', 'D', 'B', 'E', '@', '@']\n",
      "['A', 'B', 'E', '@', '@', '@'] ['A', 'B', 'E', '@', '@', '@']\n",
      "['A', 'A', 'D', '@', '@', '@'] ['D', 'B', 'A', '@', '@', '@']\n",
      "['B', 'D', 'C', 'A', '@', '@'] ['B', 'C', 'E', 'D', '@', '@']\n",
      "['B', 'E', 'C', '@', '@', '@'] ['B', 'C', 'E', '@', '@', '@']\n",
      "['B', 'C', '@', '@', '@', '@'] ['B', 'C', '@', '@', '@', '@']\n",
      "['A', 'D', 'B', '@', '@', '@'] ['A', 'D', 'B', '@', '@', '@']\n",
      "['A', 'D', 'B', '@', '@', '@'] ['A', 'D', 'B', '@', '@', '@']\n",
      "['E', 'A', '@', '@', '@', '@'] ['E', 'A', '@', '@', '@', '@']\n",
      "['E', 'A', 'D', '@', '@', '@'] ['E', 'A', 'D', '@', '@', '@']\n",
      "['B', 'E', 'E', '@', '@', '@'] ['B', 'E', 'A', '@', '@', '@']\n",
      "['B', 'F', 'A', 'C', '@', '@'] ['B', 'E', 'A', 'C', '@', '@']\n",
      "['B', 'E', 'E', '@', '@', '@'] ['B', 'E', 'A', '@', '@', '@']\n",
      "['B', 'E', 'A', 'C', '@', '@'] ['B', 'E', 'A', 'C', '@', '@']\n",
      "['C', 'E', 'E', '@', '@', '@'] ['C', 'E', 'A', '@', '@', '@']\n",
      "['C', 'A', 'A', 'B', '@', '@'] ['C', 'E', 'A', 'D', '@', '@']\n",
      "['C', 'D', 'D', '@', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'D', 'D', 'B', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'A', 'D', 'A', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'D', 'D', 'B', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'D', 'D', 'A', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'B', 'D', 'E', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['B', 'D', '@', '@', '@', '@'] ['B', 'A', '@', '@', '@', '@']\n",
      "['C', 'D', 'D', 'E', '@', '@'] ['C', 'E', 'D', 'A', '@', '@']\n",
      "['C', 'D', 'E', '@', '@', '@'] ['C', 'E', 'D', '@', '@', '@']\n",
      "['B', 'A', 'A', '@', '@', '@'] ['B', 'A', 'C', '@', '@', '@']\n",
      "['B', 'E', 'E', '@', '@', '@'] ['B', 'A', 'C', 'E', '@', '@']\n",
      "['A', 'E', 'E', '@', '@', '@'] ['A', 'E', 'D', '@', '@', '@']\n",
      "['A', 'B', 'D', 'C', '@', '@'] ['A', 'E', 'D', 'C', '@', '@']\n",
      "['A', 'E', '@', '@', '@', '@'] ['A', 'E', '@', '@', '@', '@']\n",
      "['C', 'A', 'A', '@', '@', '@'] ['C', 'A', 'E', '@', '@', '@']\n",
      "['D', 'B', '@', '@', '@', '@'] ['D', 'B', '@', '@', '@', '@']\n",
      "['B', 'E', 'C', 'D', '@', '@'] ['B', 'A', 'D', 'E', '@', '@']\n",
      "['B', 'E', 'D', 'A', '@', '@'] ['B', 'A', 'D', '@', '@', '@']\n",
      "['B', 'D', '@', '@', '@', '@'] ['B', 'A', '@', '@', '@', '@']\n",
      "['E', 'A', '@', '@', '@', '@'] ['E', 'A', '@', '@', '@', '@']\n",
      "['E', 'E', '@', '@', '@', '@'] ['E', 'B', '@', '@', '@', '@']\n",
      "['E', 'D', 'D', '@', '@', '@'] ['E', 'B', 'D', '@', '@', '@']\n",
      "['E', 'B', 'A', 'D', '@', '@'] ['E', 'B', 'D', 'A', '@', '@']\n",
      "['E', 'C', 'D', 'B', '@', '@'] ['E', 'D', 'C', 'A', '@', '@']\n",
      "['E', 'B', 'B', '@', '@', '@'] ['E', 'B', 'A', '@', '@', '@']\n",
      "['B', 'E', '@', '@', '@', '@'] ['B', 'E', '@', '@', '@', '@']\n",
      "['B', 'E', 'A', '@', '@', '@'] ['B', 'E', 'A', '@', '@', '@']\n",
      "['B', 'F', 'A', 'C', '@', '@'] ['B', 'E', 'A', 'D', '@', '@']\n",
      "['A', 'A', 'D', '@', '@', '@'] ['A', 'E', 'B', '@', '@', '@']\n",
      "['A', 'E', 'B', '@', '@', '@'] ['A', 'C', 'B', '@', '@', '@']\n",
      "['A', 'B', 'B', 'D', '@', '@'] ['A', 'C', 'B', 'E', '@', '@']\n",
      "['C', 'E', 'D', 'B', 'D', '@'] ['C', 'E', 'D', 'B', '@', '@']\n",
      "['C', 'E', 'E', 'B', '@', '@'] ['C', 'E', 'D', 'B', '@', '@']\n",
      "['B', 'E', 'C', 'D', '@', '@'] ['B', 'E', 'C', 'D', '@', '@']\n",
      "['B', 'F', 'A', '@', '@', '@'] ['B', 'E', 'C', 'A', '@', '@']\n",
      "['B', 'A', 'A', 'C', '@', '@'] ['B', 'E', 'C', 'A', 'D', '@']\n",
      "['B', 'E', 'A', '@', '@', '@'] ['B', 'E', 'C', 'A', '@', '@']\n",
      "['B', 'E', 'A', 'A', '@', '@'] ['B', 'E', 'C', 'A', 'D', '@']\n",
      "['E', 'C', 'F', '@', '@', '@'] ['E', 'C', 'F', '@', '@', '@']\n",
      "['D', 'B', 'C', '@', '@', '@'] ['D', 'B', 'A', '@', '@', '@']\n",
      "['F', 'A', 'B', '@', '@', '@'] ['F', 'B', 'A', '@', '@', '@']\n",
      "['E', 'C', 'D', 'F', 'D', '@'] ['E', 'C', 'F', 'B', 'A', '@']\n",
      "['E', 'C', 'D', 'F', 'D', '@'] ['E', 'C', 'F', 'B', 'A', '@']\n",
      "['F', 'C', 'D', 'B', '@', '@'] ['E', 'C', 'F', 'B', 'A', '@']\n",
      "['E', 'C', 'F', 'F', 'D', '@'] ['E', 'C', 'F', 'B', 'A', '@']\n",
      "['E', 'C', 'F', 'F', 'D', '@'] ['E', 'C', 'F', 'B', 'A', '@']\n",
      "['E', 'A', 'D', 'C', 'B', '@'] ['E', 'C', 'D', 'B', 'A', '@']\n",
      "['E', 'C', 'E', 'B', 'D', '@'] ['E', 'C', 'D', 'B', 'A', '@']\n",
      "['E', 'B', 'A', 'E', '@', '@'] ['E', 'C', 'D', 'B', 'A', '@']\n",
      "['B', 'D', '@', '@', '@', '@'] ['B', 'E', '@', '@', '@', '@']\n",
      "['A', 'A', '@', '@', '@', '@'] ['A', 'B', '@', '@', '@', '@']\n",
      "['B', 'E', 'B', '@', '@', '@'] ['A', 'B', 'E', '@', '@', '@']\n",
      "['A', 'E', 'F', 'C', '@', '@'] ['A', 'B', 'E', 'C', '@', '@']\n",
      "['A', 'E', 'D', 'C', 'C', '@'] ['A', 'B', 'E', 'C', 'D', '@']\n",
      "['C', 'D', '@', '@', '@', '@'] ['C', 'B', '@', '@', '@', '@']\n",
      "['C', 'B', 'B', '@', '@', '@'] ['C', 'B', 'F', '@', '@', '@']\n",
      "['C', 'D', 'D', 'D', '@', '@'] ['C', 'B', 'F', 'D', '@', '@']\n",
      "['C', 'D', 'A', 'D', '@', '@'] ['C', 'B', 'F', 'D', 'A', '@']\n",
      "['E', 'B', 'F', 'F', '@', '@'] ['E', 'C', 'A', 'D', 'F', '@']\n",
      "['B', 'D', 'A', 'A', 'F', '@'] ['E', 'D', 'B', 'A', '@', '@']\n",
      "['E', 'C', 'F', 'C', '@', '@'] ['E', 'C', 'A', 'D', 'F', '@']\n",
      "['E', 'C', 'E', 'F', '@', '@'] ['E', 'C', 'A', 'D', 'F', '@']\n",
      "['F', 'A', 'A', 'C', '@', '@'] ['F', 'A', 'B', 'E', 'D', '@']\n",
      "['F', 'A', 'F', 'C', 'B', '@'] ['F', 'A', 'B', 'E', 'D', '@']\n",
      "['F', 'A', 'F', 'C', 'B', '@'] ['F', 'A', 'B', 'E', 'D', '@']\n",
      "['F', 'A', 'B', 'C', 'B', '@'] ['F', 'A', 'B', 'E', 'D', '@']\n",
      "['B', 'C', 'F', '@', '@', '@'] ['B', 'F', 'E', '@', '@', '@']\n",
      "['B', 'C', 'D', '@', '@', '@'] ['B', 'F', 'E', '@', '@', '@']\n",
      "['C', 'B', 'E', 'B', '@', '@'] ['C', 'B', 'F', 'E', '@', '@']\n",
      "['C', 'E', 'E', 'B', 'D', '@'] ['C', 'B', 'F', 'E', '@', '@']\n",
      "['B', 'B', 'D', '@', '@', '@'] ['F', 'B', 'D', 'C', '@', '@']\n",
      "['B', 'C', 'C', 'D', '@', '@'] ['E', 'F', 'D', 'B', 'C', '@']\n",
      "['B', 'C', 'D', 'D', '@', '@'] ['E', 'F', 'D', 'B', '@', '@']\n",
      "['D', 'E', 'D', '@', '@', '@'] ['E', 'F', 'D', '@', '@', '@']\n",
      "['E', 'E', '@', '@', '@', '@'] ['E', 'F', '@', '@', '@', '@']\n",
      "['C', 'E', 'C', 'D', '@', '@'] ['E', 'F', 'D', 'B', 'C', '@']\n",
      "['E', 'C', 'D', '@', '@', '@'] ['E', 'F', 'D', 'B', '@', '@']\n",
      "['E', 'C', 'D', '@', '@', '@'] ['E', 'F', 'D', '@', '@', '@']\n",
      "['E', 'D', '@', '@', '@', '@'] ['E', 'F', '@', '@', '@', '@']\n",
      "['E', 'C', 'B', 'E', '@', '@'] ['E', 'F', 'D', 'B', 'C', '@']\n",
      "['E', 'E', 'B', '@', '@', '@'] ['E', 'F', 'D', 'B', '@', '@']\n",
      "['E', 'E', '@', '@', '@', '@'] ['E', 'F', 'D', '@', '@', '@']\n",
      "['E', 'E', '@', '@', '@', '@'] ['E', 'F', '@', '@', '@', '@']\n",
      "['C', 'B', 'F', '@', '@', '@'] ['E', 'F', 'C', '@', '@', '@']\n",
      "['A', 'B', 'E', 'C', 'D', '@'] ['A', 'B', 'E', 'F', 'C', '@']\n",
      "['A', 'B', 'F', 'C', 'E', '@'] ['A', 'B', 'E', 'F', 'C', '@']\n",
      "['A', 'B', 'F', 'C', 'E', '@'] ['A', 'B', 'E', 'F', 'C', '@']\n",
      "['E', 'A', 'F', '@', '@', '@'] ['E', 'A', 'C', '@', '@', '@']\n",
      "['E', 'A', 'F', 'D', '@', '@'] ['E', 'A', 'C', 'D', '@', '@']\n",
      "['E', 'A', 'F', 'F', 'D', '@'] ['E', 'A', 'C', 'D', 'F', '@']\n",
      "['F', 'A', 'B', '@', '@', '@'] ['F', 'A', 'C', '@', '@', '@']\n",
      "['F', 'F', 'B', '@', '@', '@'] ['F', 'A', 'C', 'D', '@', '@']\n",
      "['F', 'A', 'B', 'D', '@', '@'] ['F', 'A', 'C', 'D', 'B', '@']\n",
      "['A', 'D', 'E', '@', '@', '@'] ['A', 'D', 'E', '@', '@', '@']\n",
      "['C', 'D', 'E', 'A', '@', '@'] ['A', 'D', 'E', 'C', '@', '@']\n",
      "['A', 'B', 'A', 'C', '@', '@'] ['A', 'D', 'E', 'C', '@', '@']\n",
      "['C', 'D', 'F', '@', '@', '@'] ['C', 'D', 'F', '@', '@', '@']\n",
      "['E', 'A', 'B', '@', '@', '@'] ['E', 'F', 'A', 'B', 'D', '@']\n",
      "['C', 'E', 'F', '@', '@', '@'] ['C', 'F', 'E', '@', '@', '@']\n",
      "['D', 'A', 'F', '@', '@', '@'] ['D', 'F', 'A', '@', '@', '@']\n",
      "['A', 'B', 'D', '@', '@', '@'] ['E', 'F', 'D', '@', '@', '@']\n",
      "['D', 'D', 'E', '@', '@', '@'] ['D', 'B', '@', '@', '@', '@']\n",
      "['F', 'D', 'D', 'F', '@', '@'] ['F', 'D', 'B', '@', '@', '@']\n",
      "['E', 'A', 'D', '@', '@', '@'] ['E', 'F', 'D', 'B', '@', '@']\n",
      "['A', 'B', 'E', 'C', '@', '@'] ['A', 'C', 'E', 'F', 'B', '@']\n",
      "['A', 'B', 'E', 'C', 'E', '@'] ['A', 'C', 'E', 'F', 'B', '@']\n",
      "['A', 'E', 'D', 'C', 'B', '@'] ['A', 'C', 'E', 'F', 'B', '@']\n",
      "['A', 'B', 'F', 'C', 'B', '@'] ['A', 'C', 'E', 'F', 'B', '@']\n",
      "['E', 'E', 'A', 'F', 'D', '@'] ['D', 'F', 'B', 'A', 'C', 'E']\n",
      "['E', 'C', 'A', 'F', 'D', 'B'] ['D', 'F', 'B', 'A', 'C', 'E']\n",
      "['A', 'C', 'E', '@', '@', '@'] ['A', 'E', 'C', '@', '@', '@']\n",
      "['C', 'B', '@', '@', '@', '@'] ['C', 'B', '@', '@', '@', '@']\n",
      "['C', 'B', 'A', '@', '@', '@'] ['C', 'B', 'D', '@', '@', '@']\n",
      "['C', 'B', 'A', 'B', '@', '@'] ['C', 'B', 'D', 'A', '@', '@']\n",
      "['C', 'B', 'A', 'E', 'D', '@'] ['C', 'B', 'D', 'A', 'E', '@']\n",
      "['F', 'C', '@', 'F', '@', '@'] ['F', 'D', 'E', 'B', '@', '@']\n",
      "['A', 'E', 'F', '@', '@', '@'] ['A', 'E', 'F', '@', '@', '@']\n"
     ]
    }
   ],
   "source": [
    "def labels_to_stack(labels, n_blocks):\n",
    "    stack = []\n",
    "\n",
    "    for i in range(n_blocks):\n",
    "        block = chr(65 + labels[i].item() - 1)\n",
    "        stack.append(block)\n",
    "\n",
    "    return stack\n",
    "\n",
    "\n",
    "for item in testing_dataset:\n",
    "    input = torch.tensor(item[\"input\"]).unsqueeze(0).to(device)\n",
    "    label = item[\"labels\"].unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = probe(input).detach().cpu()\n",
    "\n",
    "    print(labels_to_stack(output.argmax(dim=-2)[0], n_blocks), labels_to_stack(label[0], n_blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = expanded_testing_data[0][\"idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = probe(torch.tensor(layer_hidden_states[0][selected_idx]).to(device)).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.argmax(dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preds = [\"\".join([chr(65 + x - 1) for x in y if x != 0]) for y in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BCEDAA',\n",
       " 'CCFFCE',\n",
       " 'BCFECE',\n",
       " 'CC',\n",
       " 'DECFFD',\n",
       " 'BEDF',\n",
       " 'BEDF',\n",
       " 'BABA',\n",
       " 'FDC',\n",
       " 'BD',\n",
       " 'FCDFD',\n",
       " 'BD',\n",
       " 'BACDFC',\n",
       " 'BDC',\n",
       " 'BD',\n",
       " 'DBC',\n",
       " 'CB',\n",
       " 'BB',\n",
       " 'B',\n",
       " 'CEDA',\n",
       " 'DEDFB',\n",
       " 'CD',\n",
       " 'BCDD',\n",
       " 'CBBCC',\n",
       " 'CBBDA',\n",
       " 'BBD',\n",
       " 'FBCDFD',\n",
       " 'BD',\n",
       " 'CB',\n",
       " 'BB',\n",
       " 'DCC',\n",
       " 'BDCA',\n",
       " 'BD',\n",
       " 'DA',\n",
       " 'DA',\n",
       " 'BA',\n",
       " 'CEC',\n",
       " 'DEC',\n",
       " 'BED',\n",
       " 'BA',\n",
       " 'BDC',\n",
       " 'BDC',\n",
       " 'CA',\n",
       " 'BCAFD',\n",
       " 'AEDA',\n",
       " 'BEDCF',\n",
       " 'CEBAF',\n",
       " 'BB',\n",
       " 'AB',\n",
       " 'BCC',\n",
       " 'BD',\n",
       " 'BDE',\n",
       " 'BAC',\n",
       " 'BE',\n",
       " 'DAC',\n",
       " 'CA',\n",
       " 'BA',\n",
       " 'BAC',\n",
       " 'BD',\n",
       " 'DB',\n",
       " 'DA',\n",
       " 'BCD',\n",
       " 'BAD',\n",
       " 'BAD',\n",
       " 'CDE',\n",
       " 'BBEEFE',\n",
       " 'AADB',\n",
       " 'CADBCE',\n",
       " 'BADDCD',\n",
       " 'CADBCF',\n",
       " 'CBAFC',\n",
       " 'BFCDC',\n",
       " 'CADECF',\n",
       " 'BFFBAD',\n",
       " 'CFE',\n",
       " 'BCADD',\n",
       " 'AFDBB',\n",
       " 'CFDFCA',\n",
       " 'ABDDC',\n",
       " 'DFDFB',\n",
       " 'BADFCE',\n",
       " 'ABFF',\n",
       " 'AACCCB',\n",
       " 'AFEFF',\n",
       " 'CFF',\n",
       " 'EDEDE',\n",
       " 'BED',\n",
       " 'BDAEDA',\n",
       " 'FDAACF',\n",
       " 'AEFDA',\n",
       " 'BDAEFA',\n",
       " 'BBAECA',\n",
       " 'CBCECC',\n",
       " 'BBEF',\n",
       " 'BDCEC',\n",
       " 'BDEC',\n",
       " 'CBCE',\n",
       " 'ADE',\n",
       " 'ADE',\n",
       " 'BD',\n",
       " 'DEAEDC',\n",
       " 'BDABBA',\n",
       " 'ABCEFA',\n",
       " 'ABCE',\n",
       " 'BB',\n",
       " 'BE',\n",
       " 'BDAAFA',\n",
       " 'BDAECA',\n",
       " 'CDCE',\n",
       " 'B',\n",
       " 'DA',\n",
       " 'BACDC',\n",
       " 'CACD',\n",
       " 'DA',\n",
       " 'CACE',\n",
       " 'B',\n",
       " 'AE',\n",
       " 'BABBA',\n",
       " 'CACE',\n",
       " 'CDCE',\n",
       " 'BE',\n",
       " 'DE',\n",
       " 'BDAEDA',\n",
       " 'BDAEEA',\n",
       " 'CACE',\n",
       " 'BACDF',\n",
       " 'AACC',\n",
       " 'BACDC',\n",
       " 'CBDDB',\n",
       " 'AE',\n",
       " 'AEC',\n",
       " 'BECDD',\n",
       " 'EE',\n",
       " 'BABBA',\n",
       " 'DACEF',\n",
       " 'CACE',\n",
       " 'BCEF',\n",
       " 'AE',\n",
       " 'BDAABA',\n",
       " 'BAEFB',\n",
       " 'AECC',\n",
       " 'BECDF',\n",
       " 'EE',\n",
       " 'BDAABA',\n",
       " 'AECEC',\n",
       " 'BECD',\n",
       " 'EADC',\n",
       " 'BBCEA',\n",
       " 'ABB',\n",
       " 'ABCE',\n",
       " 'BB',\n",
       " 'BEA',\n",
       " 'BDAABA',\n",
       " 'BCCEF',\n",
       " 'CCCE',\n",
       " 'BE',\n",
       " 'DE',\n",
       " 'BDAABA',\n",
       " 'ADCE',\n",
       " 'BDE',\n",
       " 'BACEC',\n",
       " 'BBCDA',\n",
       " 'AEB',\n",
       " 'AEC',\n",
       " 'BECD',\n",
       " 'EE',\n",
       " 'BAADA',\n",
       " 'BAEF',\n",
       " 'CACE',\n",
       " 'BACE',\n",
       " 'AE',\n",
       " 'BDAEDA',\n",
       " 'CACE',\n",
       " 'BAEF',\n",
       " 'AACEC',\n",
       " 'BBCEA',\n",
       " 'ADE',\n",
       " 'ADCE',\n",
       " 'BDE',\n",
       " 'DE',\n",
       " 'BAABA',\n",
       " 'ACDFB',\n",
       " 'ACCED',\n",
       " 'BCDD',\n",
       " 'CEA',\n",
       " 'BDADDA',\n",
       " 'ACCED',\n",
       " 'BDD',\n",
       " 'BACDD',\n",
       " 'CACDA',\n",
       " 'AAEE',\n",
       " 'CACE',\n",
       " 'BCEFD',\n",
       " 'BEDBDA',\n",
       " 'BDAEDA',\n",
       " 'DDCCF',\n",
       " 'BEA',\n",
       " 'BEFEDF',\n",
       " 'BECEDD',\n",
       " 'DEBC']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_preds[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I have this block stacking problem to solve. Let me try to figure out the steps needed to get from the initial state to the goal state. I'll take it step by step because I'm still getting the hang of these kinds of problems.\n",
      "\n",
      "First, let me understand the initial conditions. The problem says:\n",
      "\n",
      "- Block B is clear.\n",
      "- Block C is clear.\n",
      "- The hand is empty.\n",
      "- Block A is on top of Block E.\n",
      "- Block B is on top of Block D.\n",
      "- Block D is on top of Block A.\n",
      "- Block C is on the table.\n",
      "- Block E is on the table.\n",
      "\n",
      "So, visualizing this, I think the stacks are as follows:\n",
      "\n",
      "- E is on the table.\n",
      "- A is on top of E.\n",
      "- D is on top of A.\n",
      "- B is on top of D.\n",
      "- C is on the table, clear.\n",
      "\n",
      "And the goal is:\n",
      "\n",
      "- A is on top of D.\n",
      "- C is on top of A.\n",
      "- D is on top of E.\n",
      "- E is on top of B.\n",
      "\n",
      "Wait, that seems a bit confusing. Let me parse the goal again:\n",
      "\n",
      "\"Block A is on top of Block D, Block C is on top of Block A, Block D is on top of Block E and Block E is on top of Block B.\"\n",
      "\n",
      "So, the final stacks should be:\n",
      "\n",
      "- B is on the table.\n",
      "- E is on top of B.\n",
      "- D is on top of E.\n",
      "- A is on top of D.\n",
      "- C is on top of A.\n",
      "\n",
      "So, the final structure is a single stack: C on A on D on E on B.\n",
      "\n",
      "But wait, initially, E is on the table, A is on E, D is on A, B is on D. So the initial stack is B on D on A on E, and C is separate on the table.\n",
      "\n",
      "Wait, no. Let me correct that. The initial conditions say:\n",
      "\n",
      "- Block A is on top of Block E.\n",
      "- Block D is on top of Block A.\n",
      "- Block B is on top of Block D.\n",
      "\n",
      "So the initial stack is B on D on A on E, with E on the table. And Block C is on the table, clear.\n",
      "\n",
      "The goal is to have:\n",
      "\n",
      "- A on D,\n",
      "- C on A,\n",
      "- D on E,\n",
      "- E on B.\n",
      "\n",
      "So, the final stack is C on A on D on E on B. So, B is on the table, E on B, D on E, A on D, and C on A.\n",
      "\n",
      "Wait, but initially, B is on D, which is on A, which is on E. So, to get E on B, I need to move E under B, but E is currently under A and D. So, I need to move E from under A to on top of B.\n",
      "\n",
      "But E is currently supporting A, which is supporting D, which is supporting B. So, to move E, I need to first move everything above it, which is A, D, and B. But B is on D, which is on A, which is on E. So, to get E on B, I need to have B on the table, then put E on B, then stack D on E, then A on D, and finally C on A.\n",
      "\n",
      "But let's break it down step by step.\n",
      "\n",
      "First, the initial state:\n",
      "\n",
      "- Table has E and C.\n",
      "- E has A on top.\n",
      "- A has D on top.\n",
      "- D has B on top.\n",
      "- B is clear.\n",
      "- C is clear.\n",
      "\n",
      "So, the stacks are:\n",
      "\n",
      "- E (table) -> A -> D -> B\n",
      "- C (table)\n",
      "\n",
      "Goal:\n",
      "\n",
      "- B (table) -> E -> D -> A -> C\n",
      "\n",
      "So, I need to move E from under A to on top of B, which is currently on D, which is on A, which is on E. So, to move E, I need to first move A, D, and B off of E.\n",
      "\n",
      "But since E is under A, which is under D, which is under B, I need to unstack B first, then D, then A, then E can be moved.\n",
      "\n",
      "Wait, but E is on the table, so to move E, I need to pick it up, but E is under A, so A is on E. So, to pick up E, I need to have A removed from E. So, I need to unstack A from E, but A is under D and B. So, I need to unstack B first, then D, then A, then E can be moved.\n",
      "\n",
      "Let me outline the steps:\n",
      "\n",
      "1. Unstack B from D. But wait, B is on D, which is on A, which is on E. So, to unstack B, I need to have D clear. But D has B on top, so I can unstack B from D.\n",
      "\n",
      "So, step 1: Unstack B from D. Now, B is in hand, D is clear.\n",
      "\n",
      "2. Put down B on the table. Now, B is on the table, clear.\n",
      "\n",
      "3. Now, D is clear, so I can unstack D from A. So, step 3: Unstack D from A. Now, D is in hand, A is clear.\n",
      "\n",
      "4. Put down D on the table. Now, D is on the table, clear.\n",
      "\n",
      "5. Now, A is clear, so I can unstack A from E. Step 5: Unstack A from E. Now, A is in hand, E is clear.\n",
      "\n",
      "6. Put down A on the table. Now, A is on the table, clear.\n",
      "\n",
      "7. Now, E is clear, so I can pick up E. Step 7: Pick up E.\n",
      "\n",
      "8. Stack E on top of B. Now, E is on B, which is on the table. So, B has E on top.\n",
      "\n",
      "9. Now, I need to stack D on E. So, pick up D. But D is on the table, clear. So, step 9: Pick up D.\n",
      "\n",
      "10. Stack D on E. Now, D is on E, which is on B.\n",
      "\n",
      "11. Now, stack A on D. So, pick up A. A is on the table, clear. Step 11: Pick up A.\n",
      "\n",
      "12. Stack A on D. Now, A is on D, which is on E, which is on B.\n",
      "\n",
      "13. Finally, stack C on A. C is on the table, clear. So, step 13: Pick up C.\n",
      "\n",
      "14. Stack C on A. Now, C is on A, which is on D, which is on E, which is on B.\n",
      "\n",
      "Wait, but let me check if all the steps are valid according to the rules.\n",
      "\n",
      "Let me go through each step:\n",
      "\n",
      "1. Unstack B from D: Yes, because B is on D, and B is clear (since it's the top block). Hand is empty, so I can unstack B. After this, B is in hand, D is clear.\n",
      "\n",
      "2. Put down B: Now, B is on the table, clear.\n",
      "\n",
      "3. Unstack D from A: D is on A, and D is clear (since B was just removed). So, I can unstack D. Now, D is in hand, A is clear.\n",
      "\n",
      "4. Put down D: D is on the table, clear.\n",
      "\n",
      "5. Unstack A from E: A is on E, and A is clear (since D was just removed). So, I can unstack A. Now, A is in hand, E is clear.\n",
      "\n",
      "6. Put down A: A is on the table, clear.\n",
      "\n",
      "7. Pick up E: E is on the table, clear. So, I can pick it up.\n",
      "\n",
      "8. Stack E on B: B is on the table, clear. So, I can stack E on B. Now, E is on B, which is on the table.\n",
      "\n",
      "9. Pick up D: D is on the table, clear. So, I can pick it up.\n",
      "\n",
      "10. Stack D on E: E is on B, clear (since nothing is on top of E). So, I can stack D on E. Now, D is on E, which is on B.\n",
      "\n",
      "11. Pick up A: A is on the table, clear. So, I can pick it up.\n",
      "\n",
      "12. Stack A on D: D is on E, clear (since nothing is on top of D). So, I can stack A on D. Now, A is on D, which is on E, which is on B.\n",
      "\n",
      "13. Pick up C: C is on the table, clear. So, I can pick it up.\n",
      "\n",
      "14. Stack C on A: A is on D, clear (since nothing is on top of A). So, I can stack C on A. Now, C is on A, which is on D, which is on E, which is on B.\n",
      "\n",
      "Wait, but in the initial state, Block C is on the table and clear. So, in step 13, I can pick up C because it's clear. Then stack it on A, which is clear after step 12.\n",
      "\n",
      "But let me check if all the intermediate steps are valid. For example, after step 8, E is on B, which is on the table. Then, in step 9, I pick up D, which is on the table. Then stack D on E, which is on B. Then pick up A, stack on D, then pick up C, stack on A.\n",
      "\n",
      "Yes, that seems to work. But let me make sure I didn't miss any steps or violate any rules.\n",
      "\n",
      "Another way to approach this is to consider the dependencies. To move E, I need to have A, D, and B off of it. So, I need to unstack B, then D, then A, then E can be moved. Then, stack E on B, then D on E, then A on D, then C on A.\n",
      "\n",
      "Wait, but in the initial state, E is under A, which is under D, which is under B. So, to get E on B, I need to move E from under A to on top of B. But to do that, I need to have B free, which requires moving D and A off of B. But B is on D, which is on A, which is on E. So, to move B, I need to have D free, which requires moving A and E. But E is under A, so I need to move A first.\n",
      "\n",
      "Wait, perhaps a better approach is to list all the blocks and their current positions and desired positions.\n",
      "\n",
      "Initial:\n",
      "\n",
      "- E: on table, supporting A\n",
      "- A: on E, supporting D\n",
      "- D: on A, supporting B\n",
      "- B: on D, clear\n",
      "- C: on table, clear\n",
      "\n",
      "Goal:\n",
      "\n",
      "- B: on table, supporting E\n",
      "- E: on B, supporting D\n",
      "- D: on E, supporting A\n",
      "- A: on D, supporting C\n",
      "- C: on A, clear\n",
      "\n",
      "So, the desired stack is C on A on D on E on B.\n",
      "\n",
      "To achieve this, I need to:\n",
      "\n",
      "1. Move B from D to the table.\n",
      "2. Move D from A to E (but E is under A, so I need to move A first).\n",
      "3. Move A from E to D (but D is on A, so I need to move D first).\n",
      "4. Move E from under A to on top of B.\n",
      "\n",
      "This seems a bit circular. Let me try to break it down.\n",
      "\n",
      "First, I need to free up E so I can move it. To do that, I need to remove A, D, and B from E. So, the order would be:\n",
      "\n",
      "- Unstack B from D\n",
      "- Unstack D from A\n",
      "- Unstack A from E\n",
      "- Then, E is free to be moved.\n",
      "\n",
      "So, step by step:\n",
      "\n",
      "1. Unstack B from D. Now, B is in hand, D is clear.\n",
      "2. Put down B on the table. Now, B is on the table, clear.\n",
      "3. Unstack D from A. Now, D is in hand, A is clear.\n",
      "4. Put down D on the table. Now, D is on the table, clear.\n",
      "5. Unstack A from E. Now, A is in hand, E is clear.\n",
      "6. Put down A on the table. Now, A is on the table, clear.\n",
      "7. Now, E is clear, so pick up E.\n",
      "8. Stack E on B. Now, E is on B, which is on the table.\n",
      "9. Now, pick up D.\n",
      "10. Stack D on E. Now, D is on E, which is on B.\n",
      "11. Pick up A.\n",
      "12. Stack A on D. Now, A is on D, which is on E, which is on B.\n",
      "13. Pick up C.\n",
      "14. Stack C on A. Now, C is on A, which is on D, which is on E, which is on B.\n",
      "\n",
      "Wait, but in the initial state, C is on the table, clear. So, after step 12, A is on D, which is on E, which is on B. Then, I can pick up C and stack it on A.\n",
      "\n",
      "Yes, that seems to work. Let me check each step for validity.\n",
      "\n",
      "1. Unstack B from D: Valid because B is on D, clear, hand is empty.\n",
      "2. Put down B: Valid, hand is empty after.\n",
      "3. Unstack D from A: Valid because D is on A, clear now that B is removed.\n",
      "4. Put down D: Valid.\n",
      "5. Unstack A from E: Valid because A is on E, clear now that D is removed.\n",
      "6. Put down A: Valid.\n",
      "7. Pick up E: Valid because E is on table, clear.\n",
      "8. Stack E on B: Valid because B is on table, clear.\n",
      "9. Pick up D: Valid because D is on table, clear.\n",
      "10. Stack D on E: Valid because E is on B, clear.\n",
      "11. Pick up A: Valid because A is on table, clear.\n",
      "12. Stack A on D: Valid because D is on E, clear.\n",
      "13. Pick up C: Valid because C is on table, clear.\n",
      "14. Stack C on A: Valid because A is on D, clear.\n",
      "\n",
      "Yes, all steps are valid. So, the plan is:\n",
      "\n",
      "1. Unstack B from D\n",
      "2. Put down B\n",
      "3. Unstack D from A\n",
      "4. Put down D\n",
      "5. Unstack A from E\n",
      "6. Put down A\n",
      "7. Pick up E\n",
      "8. Stack E on B\n",
      "9. Pick up D\n",
      "10. Stack D on E\n",
      "11. Pick up A\n",
      "12. Stack A on D\n",
      "13. Pick up C\n",
      "14. Stack C on A\n",
      "\n",
      "Wait, but in the initial state, Block C is on the table and clear, so step 13 is valid. Also, after step 12, A is on D, which is on E, which is on B. So, step 13 and 14 are valid.\n",
      "\n",
      "I think this plan works. Let me make sure I didn't miss any steps or make any mistakes in the order.\n",
      "\n",
      "Another way to think about it is to consider the dependencies. To move E, I need to have A, D, and B off of it. So, I need to move B first, then D, then A, then E can be moved. Then, stack E on B, then D on E, then A on D, then C on A.\n",
      "\n",
      "Yes, that's exactly what the plan does. So, I think this is the correct sequence.\n",
      "</think>\n",
      "\n",
      "[PLAN]\n",
      "unstack Block B from on top of Block D\n",
      "put down Block B\n",
      "unstack Block D from on top of Block A\n",
      "put down Block D\n",
      "unstack Block A from on top of Block E\n",
      "put down Block A\n",
      "pick up Block E\n",
      "stack Block E on top of Block B\n",
      "pick up Block D\n",
      "stack Block D on top of Block E\n",
      "pick up Block A\n",
      "stack Block A on top of Block D\n",
      "pick up Block C\n",
      "stack Block C on top of Block A\n",
      "[PLAN END]\n"
     ]
    }
   ],
   "source": [
    "print(correct_instances[selected_idx][\"bench_item\"][\"full_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "px.imshow only accepts 2D single-channel, RGB or RGBA images. An image of shape (6,) was provided. Alternatively, 3- or 4-D single or multichannel datasets can be visualized using the `facet_col` or/and `animation_frame` arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/openr1/lib/python3.11/site-packages/plotly/express/_imshow.py:535\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(img, zmin, zmax, origin, labels, x, y, animation_frame, facet_col, facet_col_wrap, facet_col_spacing, facet_row_spacing, color_continuous_scale, color_continuous_midpoint, range_color, title, template, width, height, aspect, contrast_rescaling, binary_string, binary_backend, binary_compression_level, binary_format, text_auto)\u001b[0m\n\u001b[1;32m    533\u001b[0m         layout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(autorange\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreversed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpx.imshow only accepts 2D single-channel, RGB or RGBA images. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn image of shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was provided. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlternatively, 3- or 4-D single or multichannel datasets can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisualized using the `facet_col` or/and `animation_frame` arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    541\u001b[0m     )\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Now build figure\u001b[39;00m\n\u001b[1;32m    544\u001b[0m col_labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: px.imshow only accepts 2D single-channel, RGB or RGBA images. An image of shape (6,) was provided. Alternatively, 3- or 4-D single or multichannel datasets can be visualized using the `facet_col` or/and `animation_frame` arguments."
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.imshow(preds[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
